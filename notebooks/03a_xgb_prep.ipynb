{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d03376a-71db-4f85-8520-e1ffc274fc90",
   "metadata": {},
   "source": [
    "# XGBoost - Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0b0d28-c2a6-4f88-963e-8ff846e52519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import json, math, pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import iqr, skew, kurtosis, entropy as shannon_entropy\n",
    "from numpy.fft import rfft, rfftfreq\n",
    "from sklearn.model_selection import GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c824b2-e961-443f-ad3b-507f16de78f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database Paths\n",
    "DATA_DIR = pathlib.Path(\"../data\")\n",
    "ARTIFACTS = pathlib.Path(DATA_DIR / \"artifacts/xgb\")\n",
    "ARTIFACTS.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e1f51f-7efc-4d40-a5cd-0e79df1886d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helpers\n",
    "ID_COLS = [\"subject\",\"experiment\"]\n",
    "TARGET_COL = \"label\"\n",
    "EXCLUDE = [\"Time\", \"subject\", \"label\", \"experiment\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973f5a5a-655f-41f0-817f-af48c4d3f584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If fs is constant (was observed ~128 Hz), set here:\n",
    "FS = 128.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add7fa80-61cf-4d13-846f-faf1d3542e8f",
   "metadata": {},
   "source": [
    "## Load Consolidated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49371d41-a185-4aa5-a68a-67f5955d0d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the unified dataframe produced earlier\n",
    "#    Expected columns: Time, subject, label, experiment, <sensor...>\n",
    "df = pd.read_parquet(DATA_DIR / \"consolidated\" / \"fall_dataset.parquet\")\n",
    "\n",
    "# Ensure sorted by time inside each experiment (defensive)\n",
    "df = df.sort_values([\"subject\",\"experiment\",\"Time\"]).reset_index(drop=True)\n",
    "\n",
    "SENSOR_COLS = [c for c in df.columns if c not in EXCLUDE]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c71b44-f5f1-42dc-b0a2-063f49586a58",
   "metadata": {},
   "source": [
    "## Feature Engineering Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcc4bde-fb53-47da-add6-a5b31d0cda9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_crossing_rate(x: np.ndarray) -> float:\n",
    "    # fraction of sign changes over length\n",
    "    s = np.signbit(x)\n",
    "    return float(np.count_nonzero(s[1:] != s[:-1])) / max(len(x)-1, 1)\n",
    "\n",
    "def rms(x: np.ndarray) -> float:\n",
    "    return float(np.sqrt(np.mean(x**2))) if len(x) else 0.0\n",
    "\n",
    "def energy(x: np.ndarray) -> float:\n",
    "    # sum of squares (optionally normalized by length)\n",
    "    return float(np.sum(x**2))\n",
    "\n",
    "def spectral_feats(x: np.ndarray, fs: float) -> dict:\n",
    "    # Real FFT\n",
    "    X = np.abs(rfft(x))\n",
    "    freqs = rfftfreq(len(x), d=1.0/fs)\n",
    "    spec_sum = np.sum(X) + 1e-12\n",
    "    # spectral centroid (amplitude-weighted mean freq)\n",
    "    centroid = float(np.sum(freqs * X) / spec_sum)\n",
    "    # simple bandpowers (0–2Hz, 2–5Hz, 5–10Hz, >10Hz) – tune as needed\n",
    "    bands = [(0,2),(2,5),(5,10),(10,fs/2)]\n",
    "    bp = {}\n",
    "    for lo, hi in bands:\n",
    "        mask = (freqs >= lo) & (freqs < hi)\n",
    "        bp[f\"bp_{lo}_{hi}\"] = float(np.sum(X[mask]))\n",
    "    return {\"spec_centroid\": centroid, **bp}\n",
    "\n",
    "def entropy_hist(x: np.ndarray, bins: int = 32) -> float:\n",
    "    # Shannon entropy of normalized histogram\n",
    "    hist, _ = np.histogram(x, bins=bins, density=True)\n",
    "    p = hist / (np.sum(hist) + 1e-12)\n",
    "    return float(shannon_entropy(p + 1e-12, base=2))\n",
    "\n",
    "def summarize_1d(x: np.ndarray, fs: float) -> dict:\n",
    "    x = x.astype(float)\n",
    "    feats = {\n",
    "        \"mean\": float(np.mean(x)),\n",
    "        \"std\": float(np.std(x, ddof=1)) if len(x) > 1 else 0.0,\n",
    "        \"min\": float(np.min(x)),\n",
    "        \"max\": float(np.max(x)),\n",
    "        \"median\": float(np.median(x)),\n",
    "        \"iqr\": float(iqr(x)) if len(x) > 1 else 0.0,\n",
    "        \"skew\": float(skew(x)) if len(x) > 2 else 0.0,\n",
    "        \"kurtosis\": float(kurtosis(x, fisher=True)) if len(x) > 3 else 0.0,\n",
    "        \"rms\": rms(x),\n",
    "        \"energy\": energy(x),\n",
    "        \"zcr\": zero_crossing_rate(x),\n",
    "        \"entropy\": entropy_hist(x, bins=32),\n",
    "    }\n",
    "    feats.update(spectral_feats(x, fs=fs))\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e987b940-d089-4f45-b253-eb11c217dd47",
   "metadata": {},
   "source": [
    "## Process Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffad47c1-4163-4ab3-9cf7-6bfa6521c9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Aggregate per (subject, experiment) → engineered features per sensor\n",
    "rows = []\n",
    "labels = []\n",
    "meta = []\n",
    "\n",
    "grouped = df.groupby(ID_COLS, sort=False)\n",
    "for (subject, experiment), g in grouped:\n",
    "    # optional: enforce length or handle short runs\n",
    "    # g is time-ordered due to the earlier sort\n",
    "    feature_dict = {\"subject\": subject, \"experiment\": experiment}\n",
    "\n",
    "    for col in SENSOR_COLS:\n",
    "        feats = summarize_1d(g[col].to_numpy(), fs=FS)\n",
    "        # prefix with sensor name\n",
    "        for k, v in feats.items():\n",
    "            feature_dict[f\"{col}__{k}\"] = v\n",
    "\n",
    "    rows.append(feature_dict)\n",
    "    labels.append(g[TARGET_COL].iloc[0])  # label is constant within an experiment\n",
    "    meta.append({\n",
    "        \"subject\": subject,\n",
    "        \"experiment\": experiment,\n",
    "        \"n_samples\": int(len(g)),\n",
    "        \"time_start\": float(g[\"Time\"].iloc[0]),\n",
    "        \"time_end\": float(g[\"Time\"].iloc[-1]),\n",
    "    })\n",
    "\n",
    "X = pd.DataFrame(rows).set_index([\"subject\",\"experiment\"])\n",
    "y = pd.Series(labels, index=X.index, name=\"label\")\n",
    "metadata = pd.DataFrame(meta).set_index([\"subject\",\"experiment\"])\n",
    "\n",
    "# Encode labels (string → int) but also keep mapping\n",
    "label_to_id = {lbl:i for i, lbl in enumerate(sorted(y.unique()))}\n",
    "id_to_label = {i:lbl for lbl,i in label_to_id.items()}\n",
    "y_encoded = y.map(label_to_id).astype(int)\n",
    "\n",
    "# Subject-grouped splits to avoid leakage\n",
    "subjects = X.index.get_level_values(\"subject\")\n",
    "gss = GroupShuffleSplit(test_size=0.2, n_splits=1, random_state=42)\n",
    "train_idx, test_idx = next(gss.split(X, y_encoded, groups=subjects))\n",
    "\n",
    "# Make a val split from the train set (again grouped by subject)\n",
    "train_subjects = subjects.to_numpy()[train_idx]\n",
    "gss2 = GroupShuffleSplit(test_size=0.2, n_splits=1, random_state=43)\n",
    "tr2_idx, val_idx = next(gss2.split(\n",
    "    X.iloc[train_idx], y_encoded.iloc[train_idx], groups=train_subjects\n",
    "))\n",
    "final_train_idx = train_idx[tr2_idx]\n",
    "final_val_idx   = train_idx[val_idx]\n",
    "\n",
    "splits = {\n",
    "    \"label_to_id\": label_to_id,\n",
    "    \"id_to_label\": id_to_label,\n",
    "    \"train_idx\": X.index[final_train_idx].tolist(),\n",
    "    \"val_idx\": X.index[final_val_idx].tolist(),\n",
    "    \"test_idx\": X.index[test_idx].tolist(),\n",
    "    \"strategy\": \"grouped_by_subject\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb821976-8de6-4491-bebd-c2aae65e535e",
   "metadata": {},
   "source": [
    "## Check for Split Intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a724b9-aa9f-4d9a-804d-217dde66e90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_set(tlist):\n",
    "    s = set()\n",
    "\n",
    "    for ele in tlist:\n",
    "        tup = tuple(ele)\n",
    "        s.add(tup)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad6e7a6-39d5-44db-9735-45755dd3036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idxs = to_set(splits[\"train_idx\"])\n",
    "val_idxs = to_set(splits[\"val_idx\"])\n",
    "test_idxs = to_set(splits[\"test_idx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f307e5-a035-4428-be87-3fc03308f695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train x Validation\n",
    "print(\"Train X Validation intersections:\")\n",
    "for idx in train_idxs:\n",
    "    if idx in val_idxs:\n",
    "        print(idx)\n",
    "\n",
    "# Train x Test\n",
    "print(\"Train X Test intersections:\")\n",
    "for idx in train_idxs:\n",
    "    if idx in test_idxs:\n",
    "        print(idx)\n",
    "\n",
    "# Validation x Test\n",
    "print(\"Validation X Test intersections:\")\n",
    "for idx in val_idxs:\n",
    "    if idx in test_idxs:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9327083d-b16f-4748-902f-4373c77557ca",
   "metadata": {},
   "source": [
    "## Persist Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9302db6-3314-412d-802e-cc1b36a8aaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist artifacts\n",
    "X.to_parquet(ARTIFACTS / \"X.parquet\", index=True)\n",
    "y_encoded.to_frame(\"label_id\").to_parquet(ARTIFACTS / \"y.parquet\", index=True)\n",
    "metadata.to_parquet(ARTIFACTS / \"metadata.parquet\", index=True)\n",
    "with open(ARTIFACTS / \"splits.json\", \"w\") as f:\n",
    "    json.dump(splits, f, indent=2)\n",
    "\n",
    "print(\"Saved:\", list(ARTIFACTS.iterdir()))\n",
    "print(\"Shapes → X:\", X.shape, \" y:\", y_encoded.shape)\n",
    "print(\"Class counts:\", y_encoded.value_counts().sort_index().to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7740fd7e-2ba8-42ef-9bc3-f67b54c5c61d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12cd5c6-62ff-4ec5-a1fc-726a314e093f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fa4aae-b8f2-46bd-88c5-0fbe8b783347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4842c2e2-ba07-4f22-b583-1a176ed6cc52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8045e1c-d615-4fb1-84ac-a37c2b94b208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f256fa-ea1f-4bbe-9c38-8adbb47286e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a54ec93-a12a-4c68-b51d-2865fba90e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5387c1-f4f4-41ce-beea-03b66c35faaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fall-detection)",
   "language": "python",
   "name": "fall-detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
