{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e7867f9-6c11-42f7-8856-5055a716eb1c",
   "metadata": {},
   "source": [
    "# Data Consolidation\n",
    "\n",
    "Read data from `data/raw` folder and consolidates it in a single file dataset in `data/consolidated` folder.\n",
    "\n",
    "Might take some time to run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4044c98-1c4f-4374-9cc6-13db4a5027c3",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78893f8-89c1-4a6d-9ee0-52fbe331e946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the root dataset folder\n",
    "DATASET_DIR = Path(\"../data/raw\")\n",
    "\n",
    "# Collect all XLSX files recursively\n",
    "xlsx_files = list(DATASET_DIR.rglob(\"*.xlsx\"))\n",
    "\n",
    "all_dfs = []\n",
    "\n",
    "for i,file in enumerate(xlsx_files):\n",
    "    print(i, \"/\", len(xlsx_files), \":\", file)\n",
    "    # Extract metadata from path\n",
    "    subject = file.parts[-3]   # first folder name\n",
    "    label = file.parts[-2]     # second folder name\n",
    "    experiment = file.stem     # file name without extension\n",
    "    \n",
    "    # Load xlsx into DataFrame\n",
    "    df = pd.read_excel(file, header=0)  # assumes first row is header\n",
    "    \n",
    "    # Add metadata columns\n",
    "    df[\"subject\"] = subject\n",
    "    df[\"label\"] = label\n",
    "    df[\"experiment\"] = experiment\n",
    "    \n",
    "    all_dfs.append(df)\n",
    "\n",
    "# Combine everything into a single DataFrame\n",
    "dataset_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# Quick check\n",
    "print(dataset_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78e91e7-70b6-4920-b720-13efa841e4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Col Types\n",
    "exclude_cols = [\"timestamp\", \"subject\", \"label\", \"experiment\"]\n",
    "\n",
    "for col in dataset_df.columns:\n",
    "    if col not in exclude_cols:\n",
    "        dataset_df[col] = dataset_df[col].astype(float)\n",
    "\n",
    "print(dataset_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e332a16e-1ae0-47d0-bb0c-4fb70e8ef3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data\n",
    "dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4634fb19-3b38-44fc-95e0-93b8afc4cca6",
   "metadata": {},
   "source": [
    "## Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4715b317-7340-4170-8793-6eeafedb59bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count NaN / missing values per column\n",
    "missing_counts = dataset_df.isna().sum()\n",
    "\n",
    "# Percentage of missing values per column\n",
    "missing_percent = (missing_counts / len(dataset_df)) * 100\n",
    "\n",
    "# Combine into a summary DataFrame\n",
    "missing_report = pd.DataFrame({\n",
    "    \"missing_count\": missing_counts,\n",
    "    \"missing_percent\": missing_percent\n",
    "}).sort_values(by=\"missing_count\", ascending=False)\n",
    "\n",
    "# Total missing values across the whole dataset\n",
    "total_missing = dataset_df.isna().sum().sum()\n",
    "total_cells = dataset_df.shape[0] * dataset_df.shape[1]\n",
    "total_missing_percent = (total_missing / total_cells) * 100\n",
    "\n",
    "print(missing_report)\n",
    "print(\"\\n--- Overall Missing Values ---\")\n",
    "print(f\"Total missing values: {total_missing}\")\n",
    "print(f\"Total cells: {total_cells}\")\n",
    "print(f\"Overall missing percent: {total_missing_percent:.4f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48866065-b7e7-4c8d-a70b-83f511105f46",
   "metadata": {},
   "source": [
    "## Threat Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24670fa-9ccc-4d62-bd70-51507ad5004a",
   "metadata": {},
   "source": [
    "No need, no missing values found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9764386a-a52d-41ca-99b1-9bcee04664a7",
   "metadata": {},
   "source": [
    "## Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2308090-b5f7-4136-b379-d0e25a9f0ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save original shape\n",
    "original_shape = dataset_df.shape\n",
    "\n",
    "# Drop duplicates\n",
    "dataset_df = dataset_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# New shape\n",
    "new_shape = dataset_df.shape\n",
    "\n",
    "# Report\n",
    "dropped = original_shape[0] - new_shape[0]\n",
    "print(f\"Original shape: {original_shape}\")\n",
    "print(f\"New shape: {new_shape}\")\n",
    "print(f\"Duplicates dropped: {dropped}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a40ce28-34e9-48c5-a071-eb90ace88d15",
   "metadata": {},
   "source": [
    "## Export As Feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa6fbd4-3035-4aaa-84cb-437c9491b910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned DataFrame as Parquet\n",
    "dataset_df.to_parquet(\n",
    "    Path(\"../data/consolidated/fall_dataset.parquet\"),\n",
    "    index=False,              \n",
    "    engine=\"pyarrow\",         \n",
    "    compression=\"snappy\"      \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0fd0f6-b368-4b4d-b968-8c56ebb16064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload test\n",
    "df_test = pd.read_parquet(Path(\"../data/consolidated/fall_dataset.parquet\"))\n",
    "df_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
