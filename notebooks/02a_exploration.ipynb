{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d859456a-3206-4b12-ac2e-5c465887f656",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6a8d9b-53d4-48fd-835a-d2bcacb5349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126b3616-5766-4803-bbd6-7ef8915f7c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe35ae62-04a7-4ca8-98de-7cc0097eb524",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_dataset = pd.read_parquet(Path(\"../data/consolidated/fall_dataset.parquet\"))\n",
    "df_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dba7302-ab12-488e-b375-8b10d0b08a8a",
   "metadata": {},
   "source": [
    "## Number of samples by class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f76eb4-3b9e-4bc0-b1a7-8955681c6fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "# 1) Count rows per (subject, label, experiment)\n",
    "counts = (\n",
    "    df_dataset\n",
    "    .groupby([\"subject\", \"label\", \"experiment\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    ")\n",
    "\n",
    "# 2) Summary table with percentiles\n",
    "summary_counts = (\n",
    "    counts.groupby(\"label\")[\"count\"].agg(\n",
    "        n_experiments = \"count\",\n",
    "        min  = \"min\",\n",
    "        p05  = lambda s: s.quantile(0.05),\n",
    "        p25  = lambda s: s.quantile(0.25),\n",
    "        median = \"median\",\n",
    "        p75  = lambda s: s.quantile(0.75),\n",
    "        p95  = lambda s: s.quantile(0.95),\n",
    "        max  = \"max\",\n",
    "        mean = \"mean\",\n",
    "        std  = \"std\",\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# (optional) prettier printing\n",
    "num_cols = summary_counts.columns.drop(\"label\")\n",
    "summary_counts[num_cols] = summary_counts[num_cols].round(3)\n",
    "\n",
    "print(\"Summary statistics of samples per experiment:\")\n",
    "print(summary_counts.to_string(index=False))\n",
    "\n",
    "# 3) Faceted histograms per class (zoomed, no x-axis offset)\n",
    "g = sns.FacetGrid(counts, col=\"label\", sharey=False, sharex=False, height=4)\n",
    "g.map_dataframe(sns.histplot, x=\"count\", bins=30)\n",
    "\n",
    "for ax in g.axes.flat:\n",
    "    ax.xaxis.set_major_formatter(ScalarFormatter(useOffset=False))\n",
    "    title = ax.get_title()\n",
    "\n",
    "    # sensible zooms similar to the duration plot:\n",
    "    # Tight classes (Falls/Near_Falls) around ~1921; ADLs can have longer tails.\n",
    "    data_this = counts.loc[counts[\"label\"] == title.split(\" = \")[-1], \"count\"]\n",
    "    if title in (\"Falls\", \"Near_Falls\") or title.endswith(\"Falls\") and \"Near\" in title:\n",
    "        ax.set_xlim(1890, 1960)   # ~1921 ± ~40\n",
    "    elif title == \"ADLs\":\n",
    "        # show full spread with a little padding\n",
    "        lo = max(0, data_this.min() - 25)\n",
    "        hi = data_this.max() + 25\n",
    "        ax.set_xlim(lo, hi)\n",
    "\n",
    "g.set_axis_labels(\"Number of samples per experiment\", \"Count of experiments\")\n",
    "g.set_titles(col_template=\"{col_name}\")\n",
    "plt.suptitle(\"Histogram of Sample Counts per Experiment by Class\", y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb01319-3cfd-4565-9f23-23f4db2eed5d",
   "metadata": {},
   "source": [
    "## Duration of Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac12a5ac-b241-4a90-a74e-75d5bd3c14d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "# Duration per experiment (convert µs → seconds)\n",
    "durations = df_dataset.groupby([\"subject\",\"label\", \"experiment\"])[\"Time\"].agg(\n",
    "    min_t=\"min\", max_t=\"max\"\n",
    ").reset_index()\n",
    "\n",
    "durations[\"duration_sec\"] = (durations[\"max_t\"] - durations[\"min_t\"]) / 1e6\n",
    "\n",
    "# ---- Summary table ----\n",
    "summary_dur = (\n",
    "    durations.groupby(\"label\")[\"duration_sec\"].agg(\n",
    "        count  =\"count\",\n",
    "        min    =\"min\",\n",
    "        p05    =lambda s: s.quantile(0.05),\n",
    "        p25    =lambda s: s.quantile(0.25),\n",
    "        median =\"median\",\n",
    "        p75    =lambda s: s.quantile(0.75),\n",
    "        p95    =lambda s: s.quantile(0.95),\n",
    "        max    =\"max\",\n",
    "        mean   =\"mean\",\n",
    "        std    =\"std\",\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# optional: round numeric columns for prettier printing\n",
    "num_cols = summary_dur.columns.drop(\"label\")\n",
    "summary_dur[num_cols] = summary_dur[num_cols].round(4)\n",
    "\n",
    "print(\"Summary statistics of experiment duration (seconds):\")\n",
    "print(summary_dur.to_string(index=False))\n",
    "\n",
    "# Plot\n",
    "g = sns.FacetGrid(durations, col=\"label\", sharey=False, sharex=False, height=4)\n",
    "g.map_dataframe(sns.histplot, x=\"duration_sec\", bins=30)\n",
    "\n",
    "# turn off scientific offset and optionally zoom\n",
    "for ax in g.axes.flat:\n",
    "    ax.xaxis.set_major_formatter(ScalarFormatter(useOffset=False))\n",
    "    title = ax.get_title()\n",
    "    if title in (\"Falls\", \"Near_Falls\"):\n",
    "        ax.set_xlim(14.995, 15.010)   # ~15.0 to 15.01 s window\n",
    "    elif title == \"ADLs\":\n",
    "        ax.set_xlim(14.9, 20.1)\n",
    "\n",
    "g.set_axis_labels(\"Duration (seconds)\", \"Count of experiments\")\n",
    "g.set_titles(col_template=\"{col_name}\")\n",
    "plt.suptitle(\"Histogram of Experiment Durations per Class\", y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7904f14-9238-4016-bf5e-ed280f9fecca",
   "metadata": {},
   "source": [
    "## Sample Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62130cf-150e-42e5-be77-1364d84b9f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "# 1) Per-experiment sampling stats\n",
    "def _per_experiment_freq(g):\n",
    "    # g is a sub-DataFrame for one (subject,label,experiment)\n",
    "    g = g.sort_values(\"Time\")\n",
    "    dt = g[\"Time\"].diff().dropna()  # microseconds\n",
    "    dt = dt[dt > 0]                  # guard against duplicates/non-monotonic\n",
    "    if len(dt) == 0:\n",
    "        return pd.Series({\n",
    "            \"n_samples\": len(g),\n",
    "            \"n_intervals\": 0,\n",
    "            \"median_dt_us\": np.nan,\n",
    "            \"mean_dt_us\": np.nan,\n",
    "            \"p05_dt_us\": np.nan,\n",
    "            \"p95_dt_us\": np.nan,\n",
    "            \"cv_dt\": np.nan,\n",
    "            \"large_gap_ratio\": np.nan,\n",
    "            \"freq_hz\": np.nan,\n",
    "        })\n",
    "    med = dt.median()\n",
    "    large_gap_ratio = (dt > 1.5 * med).mean()\n",
    "    return pd.Series({\n",
    "        \"n_samples\": len(g),\n",
    "        \"n_intervals\": len(dt),\n",
    "        \"median_dt_us\": med,\n",
    "        \"mean_dt_us\": dt.mean(),\n",
    "        \"p05_dt_us\": dt.quantile(0.05),\n",
    "        \"p95_dt_us\": dt.quantile(0.95),\n",
    "        \"cv_dt\": (dt.std() / dt.mean()) if dt.mean() > 0 else np.nan,\n",
    "        \"large_gap_ratio\": large_gap_ratio,\n",
    "        \"freq_hz\": 1e6 / med if med > 0 else np.nan,\n",
    "    })\n",
    "\n",
    "freq_per_exp = (\n",
    "    df_dataset\n",
    "    .groupby([\"subject\", \"label\", \"experiment\"], as_index=False)\n",
    "    .apply(_per_experiment_freq)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 2) Summary table per class (with percentiles, like before)\n",
    "summary_freq = (\n",
    "    freq_per_exp.groupby(\"label\")[\"freq_hz\"].agg(\n",
    "        n_experiments = \"count\",\n",
    "        min   = \"min\",\n",
    "        p05   = lambda s: s.quantile(0.05),\n",
    "        p25   = lambda s: s.quantile(0.25),\n",
    "        median= \"median\",\n",
    "        p75   = lambda s: s.quantile(0.75),\n",
    "        p95   = lambda s: s.quantile(0.95),\n",
    "        max   = \"max\",\n",
    "        mean  = \"mean\",\n",
    "        std   = \"std\",\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Optional: round for pretty print\n",
    "num_cols = summary_freq.columns.drop(\"label\")\n",
    "summary_freq[num_cols] = summary_freq[num_cols].round(3)\n",
    "\n",
    "print(\"Sampling frequency (Hz) per class — summary:\")\n",
    "print(summary_freq.to_string(index=False))\n",
    "\n",
    "# 3) Faceted histograms of frequency per class\n",
    "g = sns.FacetGrid(freq_per_exp, col=\"label\", sharey=False, sharex=False, height=4)\n",
    "g.map_dataframe(sns.histplot, x=\"freq_hz\", bins=30)\n",
    "\n",
    "# Nice axes (no scientific offset) + auto zoom using 5–95th percentiles\n",
    "for ax in g.axes.flat:\n",
    "    ax.xaxis.set_major_formatter(ScalarFormatter(useOffset=False))\n",
    "    lab = ax.get_title().split(\" = \")[-1]\n",
    "    x = freq_per_exp.loc[freq_per_exp[\"label\"] == lab, \"freq_hz\"].dropna().values\n",
    "    if len(x):\n",
    "        q5, q95 = np.percentile(x, [5, 95])\n",
    "        pad = max(0.05 * (q95 - q5), 0.25)  # small padding\n",
    "        ax.set_xlim(q5 - pad, q95 + pad)\n",
    "\n",
    "g.set_axis_labels(\"Sampling frequency (Hz)\", \"Count of experiments\")\n",
    "g.set_titles(col_template=\"{col_name}\")\n",
    "plt.suptitle(\"Histogram of Sampling Frequency per Class\", y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46df9eb4-983c-40a1-98d5-9cdd54c5102f",
   "metadata": {},
   "source": [
    "## Sensor behavior\n",
    "\n",
    "Ploting every sensor value over its data time to check if theres a pattern between the 3 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b425ca6a-e7b8-4e53-aa48-74b8662f2021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========================\n",
    "# Config (tweak as needed)\n",
    "# =========================\n",
    "META_COLS = {\"Time\", \"label\", \"experiment\", \"subject\"}\n",
    "LABEL_ORDER = [\"Falls\", \"Near_Falls\", \"ADLs\"]  # will auto-fallback if any is missing\n",
    "ALPHA = 0.05\n",
    "MARKER_SIZE = 0.7\n",
    "MAX_POINTS_PER_PANEL = 200_000   # per (sensor, label) subplot; auto-downsamples if exceeded\n",
    "STANDARDIZE = False              # z-score per sensor (helps when different units/scales)\n",
    "RANDOM_SEED = 42                 # for reproducible downsampling\n",
    "X_PCTL = 0.95                    # use 95th percentile duration per label for x-limit\n",
    "\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "# -------------------------\n",
    "# Identify sensor columns\n",
    "# -------------------------\n",
    "sensor_cols = [\n",
    "    c for c in df_dataset.columns\n",
    "    if c not in META_COLS and np.issubdtype(df_dataset[c].dtype, np.number)\n",
    "]\n",
    "if not sensor_cols:\n",
    "    raise ValueError(\"No numeric sensor columns found (after excluding meta cols).\")\n",
    "\n",
    "# -------------------------\n",
    "# Precompute per-(subject,label,experiment) durations in seconds\n",
    "# -------------------------\n",
    "exp_dur = (\n",
    "    df_dataset.groupby([\"subject\", \"label\", \"experiment\"])[\"Time\"]\n",
    "    .agg(min_t=\"min\", max_t=\"max\")\n",
    "    .reset_index()\n",
    ")\n",
    "exp_dur[\"duration_sec\"] = (exp_dur[\"max_t\"] - exp_dur[\"min_t\"]) / 1e6\n",
    "\n",
    "# 95th-percentile duration per label (x-limits)\n",
    "dur_by_label = (\n",
    "    exp_dur.groupby(\"label\")[\"duration_sec\"]\n",
    "    .quantile(X_PCTL)\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Optional: per-sensor stats (for standardization)\n",
    "# -------------------------\n",
    "if STANDARDIZE:\n",
    "    sensor_stats = {\n",
    "        s: (np.nanmean(df_dataset[s].to_numpy()), np.nanstd(df_dataset[s].to_numpy()) or 1.0)\n",
    "        for s in sensor_cols\n",
    "    }\n",
    "else:\n",
    "    sensor_stats = {s: (0.0, 1.0) for s in sensor_cols}\n",
    "\n",
    "# -------------------------\n",
    "# Utility: build (x,y) arrays for a label and sensor with downsampling\n",
    "# -------------------------\n",
    "def collect_xy_for_label_sensor(df_lab: pd.DataFrame, sensor: str):\n",
    "    \"\"\"\n",
    "    Returns x (seconds from experiment start) and y arrays for the chosen label+sensor,\n",
    "    potentially downsampled to MAX_POINTS_PER_PANEL.\n",
    "    \"\"\"\n",
    "    xs, ys, total_points = [], [], 0\n",
    "\n",
    "    # Iterate experiments for this label\n",
    "    for (_, _, exp), g in df_lab.groupby([\"subject\", \"label\", \"experiment\"]):\n",
    "        g = g.sort_values(\"Time\")\n",
    "        if len(g) < 2:\n",
    "            continue\n",
    "\n",
    "        # Time from experiment start (seconds)\n",
    "        t_rel_sec = (g[\"Time\"] - g[\"Time\"].iloc[0]) / 1e6\n",
    "        x = t_rel_sec.to_numpy()\n",
    "\n",
    "        y = g[sensor].to_numpy()\n",
    "        # drop NaN pairs quickly\n",
    "        m = np.isfinite(x) & np.isfinite(y)\n",
    "        if m.sum() == 0:\n",
    "            continue\n",
    "        x, y = x[m], y[m]\n",
    "\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        total_points += len(x)\n",
    "\n",
    "    if total_points == 0:\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    # Concatenate and downsample if needed\n",
    "    X = np.concatenate(xs, axis=0)\n",
    "    Y = np.concatenate(ys, axis=0)\n",
    "\n",
    "    if total_points > MAX_POINTS_PER_PANEL:\n",
    "        idx = rng.choice(total_points, size=MAX_POINTS_PER_PANEL, replace=False)\n",
    "        X, Y = X[idx], Y[idx]\n",
    "\n",
    "    # Standardize if requested (global per sensor)\n",
    "    if STANDARDIZE:\n",
    "        mu, sd = sensor_stats[sensor]\n",
    "        Y = (Y - mu) / sd\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "# -------------------------\n",
    "# Main plotting loop: one figure per sensor, 3 subplots (one per label)\n",
    "# -------------------------\n",
    "available_labels = list(df_dataset[\"label\"].dropna().unique())\n",
    "labels_to_plot = [lab for lab in LABEL_ORDER if lab in available_labels]\n",
    "# include any extra labels not in LABEL_ORDER\n",
    "labels_to_plot += [lab for lab in available_labels if lab not in labels_to_plot]\n",
    "\n",
    "for sensor in sensor_cols:\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=1, ncols=len(labels_to_plot),\n",
    "        figsize=(5.5 * len(labels_to_plot), 4.8), sharey=True\n",
    "    )\n",
    "    if len(labels_to_plot) == 1:\n",
    "        axes = [axes]  # make iterable\n",
    "\n",
    "    for ax, lab in zip(axes, labels_to_plot):\n",
    "        df_lab = df_dataset[df_dataset[\"label\"] == lab]\n",
    "        X, Y = collect_xy_for_label_sensor(df_lab, sensor)\n",
    "\n",
    "        if X.size == 0:\n",
    "            ax.set_title(f\"{lab} — {sensor}\\n(no data)\")\n",
    "            ax.set_xlabel(\"Time from start (s)\")\n",
    "            continue\n",
    "\n",
    "        # Scatter (rasterized for speed)\n",
    "        ax.scatter(X, Y, s=MARKER_SIZE, alpha=ALPHA, rasterized=True)\n",
    "        ax.set_title(f\"{lab} — {sensor}\")\n",
    "        ax.set_xlabel(\"Time from start (s)\")\n",
    "\n",
    "        # Y-label only on first subplot\n",
    "        if ax is axes[0]:\n",
    "            ax.set_ylabel(\"Sensor value\" + (\" (z-score)\" if STANDARDIZE else \"\"))\n",
    "\n",
    "        # Sensible x-limit: 0 .. 95th percentile duration for that label\n",
    "        grid_end = float(dur_by_label.get(lab, np.nan))\n",
    "        if np.isfinite(grid_end) and grid_end > 0:\n",
    "            ax.set_xlim(0.0, grid_end)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3285ff-875c-482d-b771-d2f43a080878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46732c29-1821-46d4-bdbd-e2f422a29f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cf1605-974b-4355-b448-f8c4d8fb99c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed30f905-360c-4ffa-a18c-d05902c75ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4e4798-27df-4431-99d9-02f39c7ea890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac2efe7-ba51-425c-9596-396863170a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a81b63-1da3-4bbb-966f-ec32253536e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad87c93-4f56-4395-8a2c-305300d35bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be585c3-3d21-4ab1-8801-8d1f63cb473a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c5a725-a760-48dd-bb85-bd8ff99b6c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66e5073-6a21-4dbb-8210-d5dcf9410875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7756ab08-3976-400a-945e-dbec416aa1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fall-detection)",
   "language": "python",
   "name": "fall-detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
